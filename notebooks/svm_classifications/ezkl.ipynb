{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "cf69bb3f-94e6-4dba-92cd-ce08df117d67",
            "metadata": {},
            "source": [
                "## Support Vector Machines\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "95613ee9",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Weights (W): [[ 0.08203157 -0.36939205  0.79921364  0.34779002]]\n",
                        "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
                        "         1,  1])\n"
                    ]
                }
            ],
            "source": [
                "# check if notebook is in colab\n",
                "try:\n",
                "    # install ezkl\n",
                "    import google.colab\n",
                "    import subprocess\n",
                "    import sys\n",
                "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ezkl\"])\n",
                "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"onnx\"])\n",
                "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"sk2torch\"])\n",
                "\n",
                "# rely on local installation of ezkl if the notebook is not in colab\n",
                "except:\n",
                "    pass\n",
                "\n",
                "\n",
                "# here we create and (potentially train a model)\n",
                "\n",
                "# make sure you have the dependencies required here already installed\n",
                "import json\n",
                "import numpy as np\n",
                "from sklearn.svm import SVC\n",
                "import sk2torch\n",
                "import torch\n",
                "import ezkl\n",
                "import os\n",
                "\n",
                "\n",
                "# Create a dataset of two Gaussians. There will be some overlap\n",
                "# between the two classes, which adds some uncertainty to the model.\n",
                "xs = np.array([\n",
                "    [5.1, 3.5, 1.4, 0.2],\n",
                "    [4.9, 3.0, 1.4, 0.2],\n",
                "    [4.7, 3.2, 1.3, 0.2],\n",
                "    [4.6, 3.1, 1.5, 0.2],\n",
                "    [5.0, 3.6, 1.4, 0.2],\n",
                "    [5.4, 3.9, 1.7, 0.4],\n",
                "    [4.6, 3.4, 1.4, 0.3],\n",
                "    [5.0, 3.4, 1.5, 0.2],\n",
                "    [4.4, 2.9, 1.4, 0.2],\n",
                "    [4.9, 3.1, 1.5, 0.1],\n",
                "    [7.0, 3.2, 4.7, 1.4],\n",
                "    [6.4, 3.2, 4.5, 1.5],\n",
                "    [6.9, 3.1, 4.9, 1.5],\n",
                "    [5.5, 2.3, 4.0, 1.3],\n",
                "    [6.5, 2.8, 4.6, 1.5],\n",
                "    [5.7, 2.8, 4.5, 1.3],\n",
                "    [6.3, 3.3, 4.7, 1.6],\n",
                "    [4.9, 2.4, 3.3, 1.0],\n",
                "    [6.6, 2.9, 4.6, 1.3],\n",
                "    [5.2, 2.7, 3.9, 1.4],\n",
                "])\n",
                "ys = np.array([\n",
                "    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
                "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
                "])\n",
                "\n",
                "# Train an SVM on the data and wrap it in PyTorch.\n",
                "sk_model = SVC(kernel=\"linear\")\n",
                "sk_model.fit(xs, ys)\n",
                "# Extract the weights\n",
                "W = sk_model.coef_\n",
                "\n",
                "# Print the weights\n",
                "print(\"Weights (W):\", W)\n",
                "model = sk2torch.wrap(sk_model)\n",
                "\n",
                "# Convert xs to a PyTorch tensor\n",
                "xs_tensor = torch.tensor(xs)\n",
                "\n",
                "# Use the model to predict labels\n",
                "y_hat = model.predict(xs_tensor)\n",
                "print(y_hat)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b37637c4",
            "metadata": {},
            "outputs": [],
            "source": [
                "model_path = os.path.join('network.onnx')\n",
                "compiled_model_path = os.path.join('network.compiled')\n",
                "pk_path = os.path.join('test.pk')\n",
                "vk_path = os.path.join('test.vk')\n",
                "settings_path = os.path.join('settings.json')\n",
                "\n",
                "witness_path = os.path.join('witness.json')\n",
                "data_path = os.path.join('input.json')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bab6f5d0",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(xs.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "82db373a",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n",
                "# export to onnx format\n",
                "# !!!!!!!!!!!!!!!!! This will flash a warning but it is fine !!!!!!!!!!!!!!!!!!!!!\n",
                "\n",
                "# Input to the model\n",
                "shape = xs.shape\n",
                "torch_out = y_hat\n",
                "# Export the model\n",
                "torch.onnx.export(model,               # model being run\n",
                "                  # model input (or a tuple for multiple inputs)\n",
                "                  xs_tensor,\n",
                "                  # where to save the model (can be a file or file-like object)\n",
                "                  \"network.onnx\",\n",
                "                  export_params=True,        # store the trained parameter weights inside the model file\n",
                "                  opset_version=10,          # the ONNX version to export the model to\n",
                "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
                "                  input_names=['input'],   # the model's input names\n",
                "                  output_names=['output'],  # the model's output names\n",
                "                  dynamic_axes={'input': {0: 'batch_size'},    # variable length axes\n",
                "                                'output': {0: 'batch_size'}})\n",
                "\n",
                "d = ((xs_tensor).detach().numpy()).reshape([-1]).tolist()\n",
                "\n",
                "data = dict(input_shapes=[shape],\n",
                "            input_data=[d],\n",
                "            output_data=[o.reshape([-1]).tolist() for o in torch_out])\n",
                "\n",
                "# Serialize data into file:\n",
                "json.dump(data, open(\"input.json\", 'w'))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d5e374a2",
            "metadata": {},
            "outputs": [],
            "source": [
                "!RUST_LOG=trace\n",
                "run_args = ezkl.PyRunArgs();\n",
                "run_args.variables = [(\"batch_size\", shape[0])]\n",
                "# TODO: Dictionary outputs\n",
                "res = ezkl.gen_settings(model_path, settings_path, py_run_args=run_args) \n",
                "assert res == True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ezkl.calibrate_settings(data_path, model_path, settings_path, \"resources\", scales=[4,7])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3aa4f090",
            "metadata": {},
            "outputs": [],
            "source": [
                "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
                "assert res == True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8b74dcee",
            "metadata": {},
            "outputs": [],
            "source": [
                "# srs path\n",
                "res = ezkl.get_srs(settings_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "18c8b7c7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# now generate the witness file \n",
                "\n",
                "res = ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
                "assert os.path.isfile(witness_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b1c561a8",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# HERE WE SETUP THE CIRCUIT PARAMS\n",
                "# WE GOT KEYS\n",
                "# WE GOT CIRCUIT PARAMETERS\n",
                "# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
                "\n",
                "\n",
                "\n",
                "res = ezkl.setup(\n",
                "        compiled_model_path,\n",
                "        vk_path,\n",
                "        pk_path,\n",
                "    )\n",
                "\n",
                "assert res == True\n",
                "assert os.path.isfile(vk_path)\n",
                "assert os.path.isfile(pk_path)\n",
                "assert os.path.isfile(settings_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c384cbc8",
            "metadata": {},
            "outputs": [],
            "source": [
                "# GENERATE A PROOF\n",
                "import time\n",
                "\n",
                "proof_path = os.path.join('test.pf')\n",
                "# log time it takes to generate proof\n",
                "start = time.time()\n",
                "\n",
                "res = ezkl.prove(\n",
                "        witness_path,\n",
                "        compiled_model_path,\n",
                "        pk_path,\n",
                "        proof_path,\n",
                "        \"single\",\n",
                "    )\n",
                "end = time.time()\n",
                "proving_time = end - start\n",
                "print(\"PROOF GENERATION TIME: \", proving_time)\n",
                "\n",
                "# define the path that stores the benchmarking results\n",
                "benchmark_path = os.path.join('../../benchmarks.json')\n",
                "\n",
                "# check that a benchmark path exists. If not, create one. Otherwise, load the existing one\n",
                "if not os.path.isfile(benchmark_path):\n",
                "    data = {\n",
                "        \"svm_classifications\": {\n",
                "            \"ezkl\": {\n",
                "                \"provingTime\": proving_time\n",
                "            },\n",
                "            \"riscZero\": {}\n",
                "        }\n",
                "    }\n",
                "    with open(benchmark_path, 'w') as f:\n",
                "        json.dump(data, open(benchmark_path, 'w'))\n",
                "else:\n",
                "    with open(benchmark_path, 'r') as f:\n",
                "        benchmark = json.load(f)\n",
                "\n",
                "    proving_time =str(proving_time) + \"s\"\n",
                "\n",
                "    # Update the proving time in the loaded benchmark\n",
                "    benchmark['svm_classifications']['ezkl']['provingTime'] = proving_time\n",
                "    \n",
                "\n",
                "    # Write the updated benchmark back to the file\n",
                "    with open(benchmark_path, 'w') as f:\n",
                "        json.dump(benchmark, f, indent=4)\n",
                "\n",
                "\n",
                "print(res['instances'])\n",
                "assert os.path.isfile(proof_path)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
