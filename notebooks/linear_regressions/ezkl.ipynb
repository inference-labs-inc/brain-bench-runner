{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "cf69bb3f-94e6-4dba-92cd-ce08df117d67",
            "metadata": {},
            "source": [
                "## Linear Regression\n",
                "\n",
                "\n",
                "Sklearn based models are slightly finicky to get into a suitable onnx format. \n",
                "This notebook showcases how to do so using the `hummingbird-ml` python package ! "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "95613ee9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# check if notebook is in colab\n",
                "try:\n",
                "    # install ezkl\n",
                "    import google.colab\n",
                "    import subprocess\n",
                "    import sys\n",
                "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ezkl\"])\n",
                "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"onnx\"])\n",
                "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"hummingbird-ml\"])\n",
                "\n",
                "# rely on local installation of ezkl if the notebook is not in colab\n",
                "except:\n",
                "    pass\n",
                "\n",
                "import os\n",
                "import torch\n",
                "import ezkl\n",
                "import json\n",
                "from hummingbird.ml import convert\n",
                "\n",
                "\n",
                "# here we create and (potentially train a model)\n",
                "\n",
                "# make sure you have the dependencies required here already installed\n",
                "import numpy as np\n",
                "from sklearn.linear_model import LinearRegression\n",
                "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
                "# y = 1 * x_0 + 2 * x_1 + 3\n",
                "y = np.dot(X, np.array([1, 2])) + 3\n",
                "reg = LinearRegression().fit(X, y)\n",
                "reg.score(X, y)\n",
                "\n",
                "circuit = convert(reg, \"torch\", X[:1]).model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b37637c4",
            "metadata": {},
            "outputs": [],
            "source": [
                "model_path = os.path.join('network.onnx')\n",
                "compiled_model_path = os.path.join('model.compiled')\n",
                "pk_path = os.path.join('pk.key')\n",
                "vk_path = os.path.join('test.vk')\n",
                "settings_path = os.path.join('settings.json')\n",
                "\n",
                "witness_path = os.path.join('witness.json')\n",
                "data_path = os.path.join('input.json')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# export to onnx format\n",
                "# !!!!!!!!!!!!!!!!! This will flash a warning but it is fine !!!!!!!!!!!!!!!!!!!!!\n",
                "\n",
                "# Input to the model\n",
                "# read in ./input_json\n",
                "data = json.load(open(\"input.json\", 'r'))\n",
                "# convert to torch tensor\n",
                "x = torch.tensor(data['input_data'], requires_grad=True)\n",
                "torch_out = circuit(x)\n",
                "# Export the model\n",
                "torch.onnx.export(circuit,               # model being run\n",
                "                  # model input (or a tuple for multiple inputs)\n",
                "                  x,\n",
                "                  # where to save the model (can be a file or file-like object)\n",
                "                  \"network.onnx\",\n",
                "                  export_params=True,        # store the trained parameter weights inside the model file\n",
                "                  opset_version=10,          # the ONNX version to export the model to\n",
                "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
                "                  input_names=['input'],   # the model's input names\n",
                "                  output_names=['output'],  # the model's output names\n",
                "                  dynamic_axes={'input': {0: 'batch_size'},    # variable length axes\n",
                "                                'output': {0: 'batch_size'}})\n",
                "\n",
                "d = ((x).detach().numpy()).reshape([-1]).tolist()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d5e374a2",
            "metadata": {},
            "outputs": [],
            "source": [
                "!RUST_LOG=trace\n",
                "# TODO: Dictionary outputs\n",
                "res = ezkl.gen_settings(model_path, settings_path)\n",
                "assert res == True\n",
                "\n",
                "res = ezkl.calibrate_settings(data_path, model_path, settings_path, \"resources\", scales=[4,7])\n",
                "assert res == True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3aa4f090",
            "metadata": {},
            "outputs": [],
            "source": [
                "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
                "assert res == True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8b74dcee",
            "metadata": {},
            "outputs": [],
            "source": [
                "# srs path\n",
                "res = ezkl.get_srs(settings_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "18c8b7c7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# now generate the witness file \n",
                "\n",
                "res = ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
                "assert os.path.isfile(witness_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b1c561a8",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# HERE WE SETUP THE CIRCUIT PARAMS\n",
                "# WE GOT KEYS\n",
                "# WE GOT CIRCUIT PARAMETERS\n",
                "# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
                "\n",
                "\n",
                "\n",
                "res = ezkl.setup(\n",
                "        compiled_model_path,\n",
                "        vk_path,\n",
                "        pk_path,\n",
                "        \n",
                "    )\n",
                "\n",
                "assert res == True\n",
                "assert os.path.isfile(vk_path)\n",
                "assert os.path.isfile(pk_path)\n",
                "assert os.path.isfile(settings_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c384cbc8",
            "metadata": {},
            "outputs": [],
            "source": [
                "import subprocess\n",
                "import re\n",
                "import os\n",
                "import platform\n",
                "\n",
                "\n",
                "if platform.system() == 'Linux':\n",
                "    time_command = \"/usr/bin/time\"\n",
                "else:\n",
                "    time_command = \"gtime\"\n",
                "\n",
                "# Determine the correct time command based on the OS\n",
                "\n",
                "# Define the command to run with GNU time\n",
                "gnu_time_command = [time_command, \"-f\", \"%M\", \"--\"]\n",
                "ezkl_command = [\"ezkl\", \"prove\", \"--check-mode=UNSAFE\"]\n",
                "full_command = gnu_time_command + ezkl_command\n",
                "\n",
                "# Run the command and capture output\n",
                "result = subprocess.run(full_command, capture_output=True, text=True)\n",
                "\n",
                "# Extract the outputs\n",
                "output = result.stdout\n",
                "error_output = result.stderr\n",
                "\n",
                "# Use regular expression to find the \"proof took\" value\n",
                "proof_time_match = re.search(r\"proof took (\\d+\\.\\d+)\", output)\n",
                "proof_time = proof_time_match.group(1) if proof_time_match else None\n",
                "\n",
                "# Use regular expression to find the memory usage value from GNU time\n",
                "memory_usage_match = re.search(r\"(\\d+)\", error_output)\n",
                "memory_usage = memory_usage_match.group(1) if memory_usage_match else None\n",
                "\n",
                "# Display the results\n",
                "print(f\"Proof Time: {proof_time} seconds\")\n",
                "print(f\"Memory Usage: {memory_usage} KB\")\n",
                "\n",
                "\n",
                "# define the path that stores the benchmarking results\n",
                "benchmark_path = os.path.join('../../benchmarks.json')\n",
                "\n",
                "# assume benchmark file has already been created (run `bash benchmark_file.sh` to create it)\n",
                "with open(benchmark_path, 'r') as f:\n",
                "    benchmark = json.load(f)\n",
                "\n",
                "proving_time =str(proof_time) + \"s\"\n",
                "\n",
                "memory_used = str(memory_usage) + \"kb\"\n",
                "\n",
                "# Update the proving time in the loaded benchmark\n",
                "benchmark['linear_regression']['ezkl']['provingTime'].append(proving_time)\n",
                "\n",
                "# Update the memory usage in the loaded benchmark\n",
                "benchmark['linear_regression']['ezkl']['memoryUsage'].append(memory_used)\n",
                "\n",
                "# Write the updated benchmark back to the file\n",
                "with open(benchmark_path, 'w') as f:\n",
                "    json.dump(benchmark, f, indent=4)\n",
                "\n",
                "#assert proof path exists\n",
                "assert os.path.isfile('proof.json')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
