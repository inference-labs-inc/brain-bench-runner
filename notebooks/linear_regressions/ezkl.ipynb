{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "cf69bb3f-94e6-4dba-92cd-ce08df117d67",
            "metadata": {},
            "source": [
                "## Linear Regression\n",
                "\n",
                "\n",
                "Sklearn based models are slightly finicky to get into a suitable onnx format. \n",
                "This notebook showcases how to do so using the `hummingbird-ml` python package ! "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "95613ee9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# check if notebook is in colab\n",
                "try:\n",
                "    # install ezkl\n",
                "    import google.colab\n",
                "    import subprocess\n",
                "    import sys\n",
                "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ezkl\"])\n",
                "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"onnx\"])\n",
                "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"hummingbird-ml\"])\n",
                "\n",
                "# rely on local installation of ezkl if the notebook is not in colab\n",
                "except:\n",
                "    pass\n",
                "\n",
                "import os\n",
                "import torch\n",
                "import ezkl\n",
                "import json\n",
                "from hummingbird.ml import convert\n",
                "\n",
                "\n",
                "# here we create and (potentially train a model)\n",
                "\n",
                "# make sure you have the dependencies required here already installed\n",
                "import numpy as np\n",
                "from sklearn.linear_model import LinearRegression\n",
                "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
                "# y = 1 * x_0 + 2 * x_1 + 3\n",
                "y = np.dot(X, np.array([1, 2])) + 3\n",
                "reg = LinearRegression().fit(X, y)\n",
                "reg.score(X, y)\n",
                "\n",
                "circuit = convert(reg, \"torch\", X[:1]).model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b37637c4",
            "metadata": {},
            "outputs": [],
            "source": [
                "model_path = os.path.join('network.onnx')\n",
                "compiled_model_path = os.path.join('network.compiled')\n",
                "pk_path = os.path.join('test.pk')\n",
                "vk_path = os.path.join('test.vk')\n",
                "settings_path = os.path.join('settings.json')\n",
                "\n",
                "witness_path = os.path.join('witness.json')\n",
                "data_path = os.path.join('input.json')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# export to onnx format\n",
                "# !!!!!!!!!!!!!!!!! This will flash a warning but it is fine !!!!!!!!!!!!!!!!!!!!!\n",
                "\n",
                "# Input to the model\n",
                "# read in ./input_json\n",
                "data = json.load(open(\"input.json\", 'r'))\n",
                "# convert to torch tensor\n",
                "x = torch.tensor(data['input_data'], requires_grad=True)\n",
                "torch_out = circuit(x)\n",
                "# Export the model\n",
                "torch.onnx.export(circuit,               # model being run\n",
                "                  # model input (or a tuple for multiple inputs)\n",
                "                  x,\n",
                "                  # where to save the model (can be a file or file-like object)\n",
                "                  \"network.onnx\",\n",
                "                  export_params=True,        # store the trained parameter weights inside the model file\n",
                "                  opset_version=10,          # the ONNX version to export the model to\n",
                "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
                "                  input_names=['input'],   # the model's input names\n",
                "                  output_names=['output'],  # the model's output names\n",
                "                  dynamic_axes={'input': {0: 'batch_size'},    # variable length axes\n",
                "                                'output': {0: 'batch_size'}})\n",
                "\n",
                "d = ((x).detach().numpy()).reshape([-1]).tolist()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d5e374a2",
            "metadata": {},
            "outputs": [],
            "source": [
                "!RUST_LOG=trace\n",
                "# TODO: Dictionary outputs\n",
                "res = ezkl.gen_settings(model_path, settings_path)\n",
                "assert res == True\n",
                "\n",
                "res = ezkl.calibrate_settings(data_path, model_path, settings_path, \"resources\", scales=[4,7])\n",
                "assert res == True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3aa4f090",
            "metadata": {},
            "outputs": [],
            "source": [
                "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
                "assert res == True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8b74dcee",
            "metadata": {},
            "outputs": [],
            "source": [
                "# srs path\n",
                "res = ezkl.get_srs(settings_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "18c8b7c7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# now generate the witness file \n",
                "\n",
                "res = ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
                "assert os.path.isfile(witness_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b1c561a8",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# HERE WE SETUP THE CIRCUIT PARAMS\n",
                "# WE GOT KEYS\n",
                "# WE GOT CIRCUIT PARAMETERS\n",
                "# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
                "\n",
                "\n",
                "\n",
                "res = ezkl.setup(\n",
                "        compiled_model_path,\n",
                "        vk_path,\n",
                "        pk_path,\n",
                "        \n",
                "    )\n",
                "\n",
                "assert res == True\n",
                "assert os.path.isfile(vk_path)\n",
                "assert os.path.isfile(pk_path)\n",
                "assert os.path.isfile(settings_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c384cbc8",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import time\n",
                "import subprocess\n",
                "\n",
                "def get_memory_usage(pid):\n",
                "    \"\"\"Function to get memory usage of process by PID.\"\"\"\n",
                "    try:\n",
                "        # Execute Bash command to get memory usage\n",
                "        process = subprocess.Popen(['ps', '-o', 'rss=', '-p', str(pid)],\n",
                "                                   stdout=subprocess.PIPE,\n",
                "                                   stderr=subprocess.PIPE)\n",
                "        stdout, stderr = process.communicate()\n",
                "        # Convert output to int and return\n",
                "        return int(stdout)\n",
                "    except Exception as e:\n",
                "        print(f\"Error getting memory usage: {e}\")\n",
                "        return 0\n",
                "\n",
                "proof_path = os.path.join('test.pf')\n",
                "# log time and memory it takes to generate proof\n",
                "start = time.time()\n",
                "pid = os.getpid()\n",
                "initial_memory = get_memory_usage(pid)\n",
                "\n",
                "res = ezkl.prove(\n",
                "    witness_path,\n",
                "    compiled_model_path,\n",
                "    pk_path,\n",
                "    proof_path,\n",
                "    \"single\",\n",
                ")\n",
                "\n",
                "end = time.time()\n",
                "proving_time = end - start\n",
                "final_memory = get_memory_usage(pid)\n",
                "memory_used = final_memory - initial_memory\n",
                "\n",
                "print(\"PROOF GENERATION TIME: \", proving_time)\n",
                "print(\"MEMORY USAGE: \", memory_used, \"KB\")\n",
                "\n",
                "# define the path that stores the benchmarking results\n",
                "benchmark_path = os.path.join('../../benchmarks.json')\n",
                "\n",
                "# assume benchmark file has already been created (run `bash benchmark_file.sh` to create it)\n",
                "with open(benchmark_path, 'r') as f:\n",
                "    benchmark = json.load(f)\n",
                "\n",
                "proving_time =str(proving_time) + \"s\"\n",
                "\n",
                "memory_used = str(memory_used) + \"kb\"\n",
                "\n",
                "# Update the proving time in the loaded benchmark\n",
                "benchmark['linear_regressions']['ezkl']['provingTime'].append(proving_time)\n",
                "\n",
                "# Update the memory usage in the loaded benchmark\n",
                "benchmark['linear_regressions']['ezkl']['memoryUsage'].append(memory_used)\n",
                "\n",
                "\n",
                "# Write the updated benchmark back to the file\n",
                "with open(benchmark_path, 'w') as f:\n",
                "    json.dump(benchmark, f, indent=4)\n",
                "\n",
                "\n",
                "print(res['instances'])\n",
                "assert os.path.isfile(proof_path)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
