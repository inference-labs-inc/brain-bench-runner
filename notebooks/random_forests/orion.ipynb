{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5LebDdijvVl"
      },
      "source": [
        "# Converter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnrxwrhEd6oE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from starknet_py.hash.utils import pedersen_hash\n",
        "\n",
        "def float_to_fixed_point(value, integer_bits, fractional_bits):\n",
        "    scale_factor = 2**fractional_bits\n",
        "    return f\"FP{integer_bits}x{fractional_bits} {{ mag: {abs(int(value * scale_factor))}, sign: {str(value < 0).lower()} }}\"\n",
        "\n",
        "def cairo_array(arr, type_name=\"usize\", fixed_point_type=\"FP16x16\"):\n",
        "    if type_name.startswith(\"FP\"):\n",
        "        integer_bits, fractional_bits = map(int, fixed_point_type[2:].split('x'))\n",
        "        return \", \".join([float_to_fixed_point(x, integer_bits, fractional_bits) for x in arr])\n",
        "    return \", \".join(map(str, arr))\n",
        "\n",
        "\n",
        "class TreeEnsembleAttributes:\n",
        "    def __init__(self):\n",
        "        self._names = []\n",
        "\n",
        "    def add(self, name, value):\n",
        "        if not name.endswith(\"_as_tensor\"):\n",
        "            self._names.append(name)\n",
        "        if isinstance(value, list):\n",
        "            dtype = np.float32 if name in {\"base_values\", \"class_weights\", \"nodes_values\", \"nodes_hitrates\"} else None\n",
        "            value = np.array(value, dtype=dtype)\n",
        "        setattr(self, name, value)\n",
        "\n",
        "class TreeEnsemble:\n",
        "    def __init__(self, fixed_point_type=\"FP16x16\", **kwargs):\n",
        "        self.atts = TreeEnsembleAttributes()\n",
        "        self.fixed_point_type = fixed_point_type\n",
        "        for name, value in kwargs.items():\n",
        "            self.atts.add(name, value)\n",
        "\n",
        "        self.tree_ids = sorted(set(self.atts.nodes_treeids))\n",
        "        self._initialize_indices()\n",
        "\n",
        "    def _initialize_indices(self):\n",
        "        self.root_index = {tid: len(self.atts.nodes_treeids) for tid in self.tree_ids}\n",
        "        for index, tree_id in enumerate(self.atts.nodes_treeids):\n",
        "            self.root_index[tree_id] = min(self.root_index[tree_id], index)\n",
        "        self.node_index = {(tid, nid): i for i, (tid, nid) in enumerate(zip(self.atts.nodes_treeids, self.atts.nodes_nodeids))}\n",
        "\n",
        "    def generate_cairo_code(self):\n",
        "        tree_ids_cairo = f\"let tree_ids: Span<usize> = array![{cairo_array(self.tree_ids)}].span();\"\n",
        "        root_index_cairo = self._generate_root_index_cairo()\n",
        "        node_index_cairo = self._generate_node_index_cairo()\n",
        "\n",
        "        return f\"{tree_ids_cairo}\\n{root_index_cairo}\\n{node_index_cairo}\"\n",
        "\n",
        "    def _generate_root_index_cairo(self):\n",
        "        root_index_lines = [f\"    root_index.insert({tid}, {self.root_index[tid]});\" for tid in self.tree_ids]\n",
        "        return \"let mut root_index: Felt252Dict<usize> = Default::default();\\n\" + \"\\n\".join(root_index_lines)\n",
        "\n",
        "    def _generate_node_index_cairo(self):\n",
        "        node_index_lines = [f\"    node_index.insert({pedersen_hash(int(tid), int(nid))}, {index});\"\n",
        "                            for (tid, nid), index in self.node_index.items()]\n",
        "        return \"let mut node_index: Felt252Dict<usize> = Default::default();\\n\" + \"\\n\".join(node_index_lines)\n",
        "\n",
        "def generate_full_cairo_code(params, fixed_point_type=\"FP16x16\"):\n",
        "    ensemble = TreeEnsemble(fixed_point_type=fixed_point_type, **params)\n",
        "    tree_specific_code = ensemble.generate_cairo_code()\n",
        "\n",
        "    # Check for base_values content\n",
        "    if params['base_values']:\n",
        "        base_values_cairo = f\"let base_values: Option<Span<{fixed_point_type}>> = Option::Some(array![{cairo_array(params['base_values'], fixed_point_type, fixed_point_type)}].span());\"\n",
        "    else:\n",
        "        base_values_cairo = f\"let base_values: Option<Span<{fixed_point_type}>> = Option::None;\"\n",
        "    \n",
        "    if params['post_transform']:\n",
        "        post_transform_cairo = params['post_transform']\n",
        "    else:\n",
        "        post_transform_cairo = \"NONE\"\n",
        "\n",
        "    return f\"\"\"\n",
        "use orion::numbers::{fixed_point_type};\n",
        "use orion::operators::tensor::{{Tensor, TensorTrait, {fixed_point_type}Tensor, U32Tensor}};\n",
        "use orion::operators::ml::tree_ensemble::core::{{NODE_MODES, TreeEnsembleAttributes, TreeEnsemble}};\n",
        "use orion::operators::ml::tree_ensemble::tree_ensemble_classifier::{{TreeEnsembleClassifier, POST_TRANSFORM, TreeEnsembleClassifierTrait}};\n",
        "use orion::operators::matrix::{{MutMatrix, MutMatrixImpl}};\n",
        "\n",
        "fn main(X: Tensor<{fixed_point_type}>) {{\n",
        "    let class_ids: Span<usize> = array![{cairo_array(params['class_ids'])}].span();\n",
        "    let class_nodeids: Span<usize> = array![{cairo_array(params['class_nodeids'])}].span();\n",
        "    let class_treeids: Span<usize> = array![{cairo_array(params['class_treeids'])}].span();\n",
        "    let class_weights: Span<{fixed_point_type}> = array![{cairo_array(params['class_weights'], fixed_point_type, fixed_point_type)}].span();\n",
        "    let classlabels: Span<usize> = array![{cairo_array(params['classlabels'])}].span();\n",
        "    let nodes_falsenodeids: Span<usize> = array![{cairo_array(params['nodes_falsenodeids'])}].span();\n",
        "    let nodes_featureids: Span<usize> = array![{cairo_array(params['nodes_featureids'])}].span();\n",
        "    let nodes_missing_value_tracks_true: Span<usize> = array![{cairo_array(params['nodes_missing_value_tracks_true'])}].span();\n",
        "    let nodes_modes: Span<NODE_MODES> = array![{', '.join(['NODE_MODES::' + x for x in params['nodes_modes']])}].span();\n",
        "    let nodes_nodeids: Span<usize> = array![{cairo_array(params['nodes_nodeids'])}].span();\n",
        "    let nodes_treeids: Span<usize> = array![{cairo_array(params['nodes_treeids'])}].span();\n",
        "    let nodes_truenodeids: Span<usize> = array![{cairo_array(params['nodes_truenodeids'])}].span();\n",
        "    let nodes_values: Span<{fixed_point_type}> = array![{cairo_array(params['nodes_values'], fixed_point_type, fixed_point_type)}].span();\n",
        "    {base_values_cairo}\n",
        "    let post_transform = POST_TRANSFORM::{post_transform_cairo};\n",
        "\n",
        "    {tree_specific_code}\n",
        "\n",
        "    let atts = TreeEnsembleAttributes {{\n",
        "        nodes_falsenodeids,\n",
        "        nodes_featureids,\n",
        "        nodes_missing_value_tracks_true,\n",
        "        nodes_modes,\n",
        "        nodes_nodeids,\n",
        "        nodes_treeids,\n",
        "        nodes_truenodeids,\n",
        "        nodes_values\n",
        "    }};\n",
        "\n",
        "    let mut ensemble: TreeEnsemble<{fixed_point_type}> = TreeEnsemble {{\n",
        "        atts, tree_ids, root_index, node_index\n",
        "    }};\n",
        "\n",
        "    let mut classifier: TreeEnsembleClassifier<{fixed_point_type}> = TreeEnsembleClassifier {{\n",
        "        ensemble,\n",
        "        class_ids,\n",
        "        class_nodeids,\n",
        "        class_treeids,\n",
        "        class_weights,\n",
        "        classlabels,\n",
        "        base_values,\n",
        "        post_transform\n",
        "    }};\n",
        "\n",
        "    let (labels, mut scores) = TreeEnsembleClassifierTrait::predict(ref classifier, X);\n",
        "}}\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QukN3k7ajj7C"
      },
      "source": [
        "# Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# make sure you have the dependencies required here already installed\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier as Rf\n",
        "from hummingbird.ml import convert\n",
        "import sk2torch\n",
        "import torch\n",
        "import ezkl\n",
        "import os\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "# Paths to the CSV files\n",
        "filepath_iris_input = \"iris_input_data.csv\"\n",
        "filepath_iris_classes = \"iris_classes.csv\"\n",
        "\n",
        "# Read the data from the CSV files\n",
        "X = pd.read_csv(filepath_iris_input).values.astype(np.float32)\n",
        "y = pd.read_csv(filepath_iris_classes).squeeze().values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "clr = Rf()\n",
        "clr.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from skl2onnx import convert_sklearn\n",
        "from skl2onnx.common.data_types import FloatTensorType\n",
        "\n",
        "# Determine the number of features in your input data\n",
        "number_of_features = X_train.shape[1]\n",
        "print(\"Number of features:\", number_of_features)\n",
        "\n",
        "# Initial types: specify the type and shape of the input data\n",
        "initial_type = [('float_input', FloatTensorType([None, number_of_features]))]\n",
        "\n",
        "# Convert the scikit-learn model to ONNX\n",
        "onnx_model = convert_sklearn(clr, initial_types=initial_type)\n",
        "\n",
        "# Save the model\n",
        "with open(\"network.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())\n",
        "\n",
        "print(\"Model exported to ONNX format as random_forest_model.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Generating Cairo files**\n",
        "\n",
        "Now let's generate Cairo files for each tensor in the object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decimal_to_fp16x16(num):\n",
        "\n",
        "    whole_num = int(num)\n",
        "    fractional_part = int((num - whole_num) * 65536)\n",
        "    fp_number = (whole_num << 16) + fractional_part\n",
        "    return fp_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "tensor_name = [\"X_test\"]\n",
        "\n",
        "base_path = os.path.join(\"../../src\")\n",
        "\n",
        "def generate_cairo_files(data, name):\n",
        "    generated_path = os.path.join(base_path, 'generated')\n",
        "    os.makedirs(generated_path, exist_ok=True)\n",
        "\n",
        "    with open(os.path.join(base_path, 'generated', f\"{name}.cairo\"), \"w\") as f:\n",
        "        f.write(\n",
        "            \"use array::ArrayTrait;\\n\" +\n",
        "            \"use orion::operators::tensor::{Tensor, TensorTrait, FP16x16Tensor};\\n\" +\n",
        "            \"use orion::numbers::{FixedTrait, FP16x16, FP16x16Impl};\\n\" +\n",
        "            \"\\n\" + f\"fn {name}() -> Tensor<FP16x16>\" + \"{\\n\\n\" + \n",
        "            \"let mut shape = ArrayTrait::new();\\n\"\n",
        "        )\n",
        "        for dim in data.shape:\n",
        "            f.write(f\"shape.append({dim});\\n\")\n",
        "    \n",
        "        f.write(\"let mut data = ArrayTrait::new();\")\n",
        "        for val in np.nditer(data.flatten()):\n",
        "            f.write(f\"data.append(FixedTrait::new({abs(int(decimal_to_fp16x16(val)))}, {str(val < 0).lower()}));\\n\")\n",
        "        f.write(\n",
        "            \"let tensor = TensorTrait::<FP16x16>::new(shape.span(), data.span());\\n\" +\n",
        "            \"return tensor;\\n}\"\n",
        "        )\n",
        "\n",
        "with open(os.path.join(base_path, 'generated.cairo'), 'w') as f:\n",
        "    for n in tensor_name:\n",
        "        f.write(f\"mod {n};\\n\")\n",
        "\n",
        "generate_cairo_files(np.array([X[0]], dtype=np.float32), \"X_test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we extract parameters from ONNX model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8-C1mDjHpeH"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "import numpy as np\n",
        "\n",
        "def extract_parameters_from_onnx(model_path):\n",
        "    # Load the ONNX model\n",
        "    model = onnx.load(model_path)\n",
        "\n",
        "    print(model.graph.node)\n",
        "\n",
        "    # Initialize parameters dictionary\n",
        "    params = {\n",
        "        'class_ids': [],\n",
        "        'class_nodeids': [],\n",
        "        'class_treeids': [],\n",
        "        'class_weights': [],\n",
        "        'classlabels': [],\n",
        "        'nodes_falsenodeids': [],\n",
        "        'nodes_featureids': [],\n",
        "        'nodes_hitrates': [],  # Might not be available in ONNX model\n",
        "        'nodes_missing_value_tracks_true': [],\n",
        "        'nodes_modes': [],\n",
        "        'nodes_nodeids': [],\n",
        "        'nodes_treeids': [],\n",
        "        'nodes_truenodeids': [],\n",
        "        'nodes_values': [],\n",
        "        'base_values': [],  # Might not be directly available\n",
        "        'post_transform': 'SOFTMAX'  # Assuming softmax, check your model\n",
        "    }\n",
        "\n",
        "    # Traverse the ONNX model graph to extract parameters\n",
        "    for node in model.graph.node:\n",
        "        if node.op_type == 'TreeEnsembleClassifier':\n",
        "            for attribute in node.attribute:\n",
        "                # Extract the parameters based on attribute names\n",
        "                # Note: The attribute names should match those in your ONNX model\n",
        "                if attribute.name in params:\n",
        "                    if attribute.name == 'nodes_modes':\n",
        "                        params[attribute.name] = [mode.decode('utf-8') for mode in attribute.strings]\n",
        "                    else:\n",
        "                        params[attribute.name] = attribute.ints if attribute.ints else attribute.floats\n",
        "\n",
        "    return params\n",
        "\n",
        "# Path to your exported ONNX model\n",
        "onnx_model_path = 'network.onnx'\n",
        "\n",
        "# Extract parameters\n",
        "parameters = extract_parameters_from_onnx(onnx_model_path)\n",
        "\n",
        "# Print parameters to check\n",
        "print(parameters)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implement the ONNX model in Cairo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! touch ../../src/helper.cairo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fixed_point_type = \"FP16x16\"  \n",
        "full_cairo_code = generate_full_cairo_code(parameters, fixed_point_type)\n",
        "# write this to ../../src/helper.cairo\n",
        "with open(os.path.join(base_path, 'helper.cairo'), 'w') as f:\n",
        "    f.write(full_cairo_code)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! touch ../../src/test.cairo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile ../../src/test.cairo\n",
        "\n",
        "use traits::TryInto;\n",
        "use array::{ArrayTrait, SpanTrait};\n",
        "use orion::operators::tensor::{\n",
        "    Tensor, TensorTrait, FP16x16Tensor, FP16x16TensorAdd, FP16x16TensorMul, FP16x16TensorSub,\n",
        "    FP16x16TensorDiv\n",
        "};\n",
        "use orion::numbers::{FixedTrait, FP16x16, FP16x16Impl};\n",
        "use orion::numbers::fixed_point::implementations::fp16x16::core::{\n",
        "    HALF, ONE, FP16x16Mul, FP16x16Div, FP16x16IntoI32, FP16x16PartialOrd,\n",
        "    FP16x16PartialEq\n",
        "};\n",
        "\n",
        "use giza::{\n",
        "    generated::{X_test::X_test}\n",
        "};\n",
        "\n",
        "use giza::{helper::main};\n",
        "\n",
        "#[test]\n",
        "#[available_gas(99999999999999999)]\n",
        "fn random_forest_test() {\n",
        "    let x_test = X_test();\n",
        "\n",
        "    let final_y_pred = main(x_test);\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! touch ../../src/lib.cairo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile ../../src/lib.cairo\n",
        "\n",
        "mod generated;\n",
        "mod test;\n",
        "mod helper;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import time\n",
        "import json\n",
        "\n",
        "import re\n",
        "    \n",
        "def extract_compilation_time(output):\n",
        "    # Use search() to find the first occurrence in the entire output string\n",
        "    match = re.search(r\"release target\\(s\\) in (\\d+) seconds\", output)\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    else:\n",
        "        print(\"No match found in the output for compilation time.\")\n",
        "        return 0\n",
        "\n",
        "def get_memory_usage(pid):\n",
        "    try:\n",
        "        ps_output = subprocess.run(['ps', '-p', str(pid), '-o', 'rss='], capture_output=True, text=True)\n",
        "        memory_usage = int(ps_output.stdout.strip())\n",
        "        return memory_usage\n",
        "    except Exception as e:\n",
        "        print(f\"Error in getting memory usage: {e}\")\n",
        "        return 0\n",
        "\n",
        "# Start the process in the background\n",
        "start_time = time.perf_counter()\n",
        "process = subprocess.Popen([\"scarb\", \"cairo-test\", \"-f\", \"random_forest_test\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "\n",
        "# Get the memory usage\n",
        "memory_usage = get_memory_usage(process.pid)\n",
        "\n",
        "# Wait for the process to complete and get output\n",
        "stdout, stderr = process.communicate()\n",
        "end_time = time.perf_counter()\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# Print the full output for debugging\n",
        "print(\"Full Output:\")\n",
        "print(stdout)\n",
        "print(stderr)\n",
        "\n",
        "# Extract the compilation time\n",
        "compilation_time = extract_compilation_time(stdout)\n",
        "\n",
        "print(f\"Compilation Time: {compilation_time} seconds\")\n",
        "print(f\"Memory Usage: {memory_usage} KB\")\n",
        "\n",
        "# Calculate proving execution time\n",
        "proving_time = total_time - compilation_time\n",
        "\n",
        "print(f\"Test Execution Time: {proving_time} seconds\")\n",
        "\n",
        "\n",
        "# define the path that stores the benchmarking results\n",
        "benchmark_path = os.path.join('../../benchmarks.json')\n",
        "\n",
        "# check that a benchmark path exists. If not, create one. Otherwise, load the existing one\n",
        "\n",
        "with open(benchmark_path, 'r') as f:\n",
        "    benchmark = json.load(f)\n",
        "\n",
        "proving_time =str(proving_time) + \"s\"\n",
        "\n",
        "memory_usage = str(memory_usage) + \"kb\"\n",
        "\n",
        "# Update the proving time in the loaded benchmark\n",
        "benchmark['random_forests']['orion']['provingTime'] = proving_time\n",
        "\n",
        "# Update the memory usage in the loaded benchmark\n",
        "benchmark['random_forests']['orion']['memoryUsage'] = memory_usage\n",
        "\n",
        "\n",
        "# Write the updated benchmark back to the file\n",
        "with open(benchmark_path, 'w') as f:\n",
        "    json.dump(benchmark, f, indent=4)\n",
        "\n",
        "# Print the result (optional)\n",
        "print(f\"Command executed in {proving_time} seconds\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
