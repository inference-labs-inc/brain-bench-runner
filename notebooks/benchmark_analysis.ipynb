{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Charts + Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def load_data(filepath):\n",
    "    try:\n",
    "        with open(filepath) as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filepath}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_data(data, model):\n",
    "    frameworks = ['ezkl', 'riscZero'] if model == 'random_forests' else ['ezkl', 'orion', 'riscZero']\n",
    "    memory_usage = {framework: np.mean([int(mu.replace('kb', '')) for mu in data[model][framework]['memoryUsage']])\n",
    "                    for framework in frameworks}\n",
    "    proving_time = {framework: np.mean([float(pt.replace('s', '')) for pt in data[model][framework]['provingTime']])\n",
    "                    for framework in frameworks}\n",
    "    return memory_usage, proving_time\n",
    "\n",
    "def plot_memory_usage(frameworks, memory_usage, title):\n",
    "    valid_frameworks = [fw for fw in frameworks if fw in memory_usage]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(np.arange(len(valid_frameworks)), [memory_usage[fw] for fw in valid_frameworks], color='b', width=0.4, align='center')\n",
    "    plt.xlabel('Frameworks')\n",
    "    plt.ylabel('Average Memory Usage (kb)', color='b')\n",
    "    plt.xticks(np.arange(len(valid_frameworks)), valid_frameworks)\n",
    "\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height, f'{height:.2f}', ha='center', va='bottom', color='black')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_proving_time(frameworks, proving_time, title):\n",
    "    valid_frameworks = [fw for fw in frameworks if fw in proving_time]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(np.arange(len(valid_frameworks)), [proving_time[fw] for fw in valid_frameworks], color='r', width=0.4, align='center')\n",
    "    plt.xlabel('Frameworks')\n",
    "    plt.ylabel('Average Proving Time (s)', color='r')\n",
    "    plt.xticks(np.arange(len(valid_frameworks)), valid_frameworks)\n",
    "\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height, f'{height:.2f}', ha='center', va='bottom', color='black')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calculate_performance(memory_usage, proving_time):\n",
    "    speedup_risczero = proving_time['riscZero'] / proving_time['ezkl']\n",
    "    reduction_risczero = (memory_usage['riscZero'] - memory_usage['ezkl']) * 100 / memory_usage['riscZero']\n",
    "\n",
    "    if 'orion' in memory_usage:\n",
    "        speedup_orion = proving_time['orion'] / proving_time['ezkl']\n",
    "        reduction_orion = (memory_usage['orion'] - memory_usage['ezkl']) * 100 / memory_usage['orion']\n",
    "        return speedup_orion, reduction_orion, speedup_risczero, reduction_risczero\n",
    "    else:\n",
    "        return None, None, speedup_risczero, reduction_risczero\n",
    "\n",
    "def print_performance(model, performance):\n",
    "    speedup_orion, reduction_orion, speedup_risczero, reduction_risczero = performance\n",
    "    statement = f\"{model} Results:\\n\\nProving Time Speedup:\\n\"\n",
    "    if speedup_orion is not None:\n",
    "        statement += f\"EZKL is approximately {speedup_orion:.2f} times faster than Orion.\\n\"\n",
    "    statement += f\"EZKL is about {speedup_risczero:.2f} times faster than RISC0.\\n\\nMemory Usage Reduction:\\n\"\n",
    "    if reduction_orion is not None:\n",
    "        statement += f\"EZKL uses roughly {reduction_orion:.2f}% less memory compared to Orion.\\n\"\n",
    "    statement += f\"EZKL's memory usage is about {reduction_risczero:.2f}% less than that of RISC0.\\n\"\n",
    "    print(statement)\n",
    "\n",
    "# Main Execution\n",
    "data = load_data('../benchmarks.json')\n",
    "if data:\n",
    "    models = ['linear_regressions', 'random_forests', 'svm_classifications', 'te_regressions']\n",
    "    frameworks = ['ezkl', 'orion', 'riscZero']\n",
    "    total_memory_usage = {framework: 0 for framework in frameworks}\n",
    "    total_proving_time = {framework: 0 for framework in frameworks}\n",
    "\n",
    "    for model in models:\n",
    "        memory_usage, proving_time = preprocess_data(data, model)\n",
    "        plot_memory_usage(frameworks, memory_usage, f'{model}: Memory Usage')\n",
    "        plot_proving_time(frameworks, proving_time, f'{model}: Proving Time')\n",
    "        performance = calculate_performance(memory_usage, proving_time)\n",
    "        print_performance(model, performance)\n",
    "        # skip random forests for mean calculations since it omits orion\n",
    "        if model == 'random_forests':\n",
    "            continue\n",
    "        for framework in frameworks:\n",
    "            total_memory_usage[framework] += memory_usage.get(framework, 0)\n",
    "            total_proving_time[framework] += proving_time.get(framework, 0)\n",
    "\n",
    "    mean_memory_usage = {fw: mu / (len(models)-1) for fw, mu in total_memory_usage.items()}\n",
    "    mean_proving_time = {fw: pt / (len(models)-1) for fw, pt in total_proving_time.items()}\n",
    "    plot_memory_usage(frameworks, mean_memory_usage, 'Mean Memory Usage Across All Models (except random forest)')\n",
    "    plot_proving_time(frameworks, mean_proving_time, 'Mean Proving Time Across All Models (except random forest)')\n",
    "    performance = calculate_performance(mean_memory_usage, mean_proving_time)\n",
    "    print_performance(\"Mean\", performance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
