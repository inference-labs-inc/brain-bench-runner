{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "cf69bb3f-94e6-4dba-92cd-ce08df117d67",
            "metadata": {},
            "source": [
                "## Linear Regression\n",
                "\n",
                "\n",
                "Sklearn based models are slightly finicky to get into a suitable onnx format. \n",
                "This notebook showcases how to do so using the `hummingbird-ml` python package ! "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "cbc2061f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Collecting hummingbird-ml\n",
                        "  Using cached hummingbird_ml-0.4.9-py2.py3-none-any.whl (165 kB)\n",
                        "Collecting onnxconverter-common>=1.6.0\n",
                        "  Using cached onnxconverter_common-1.14.0-py2.py3-none-any.whl (84 kB)\n",
                        "Collecting scipy\n",
                        "  Using cached scipy-1.11.4-cp39-cp39-macosx_12_0_arm64.whl (29.7 MB)\n",
                        "Requirement already satisfied: torch>1.7.0 in /Users/ethancemer/Documents/development/ezkl/.env/lib/python3.9/site-packages (from hummingbird-ml) (2.1.2)\n",
                        "Collecting scikit-learn\n",
                        "  Using cached scikit_learn-1.3.2-cp39-cp39-macosx_12_0_arm64.whl (9.5 MB)\n",
                        "Requirement already satisfied: protobuf>=3.20.2 in /Users/ethancemer/Documents/development/ezkl/.env/lib/python3.9/site-packages (from hummingbird-ml) (4.25.1)\n",
                        "Requirement already satisfied: numpy>=1.15 in /Users/ethancemer/Documents/development/ezkl/.env/lib/python3.9/site-packages (from hummingbird-ml) (1.21.6)\n",
                        "Requirement already satisfied: psutil in /Users/ethancemer/Documents/development/ezkl/.env/lib/python3.9/site-packages (from hummingbird-ml) (5.9.7)\n",
                        "Collecting dill\n",
                        "  Using cached dill-0.3.7-py3-none-any.whl (115 kB)\n",
                        "Collecting protobuf>=3.20.2\n",
                        "  Using cached protobuf-3.20.2-py2.py3-none-any.whl (162 kB)\n",
                        "Requirement already satisfied: onnx in /Users/ethancemer/Documents/development/ezkl/.env/lib/python3.9/site-packages (from onnxconverter-common>=1.6.0->hummingbird-ml) (1.14.1)\n",
                        "Requirement already satisfied: packaging in /Users/ethancemer/Documents/development/ezkl/.env/lib/python3.9/site-packages (from onnxconverter-common>=1.6.0->hummingbird-ml) (23.2)\n",
                        "Requirement already satisfied: networkx in /Users/ethancemer/Documents/development/ezkl/.env/lib/python3.9/site-packages (from torch>1.7.0->hummingbird-ml) (3.2.1)\n",
                        "Requirement already satisfied: filelock in /Users/ethancemer/Documents/development/ezkl/.env/lib/python3.9/site-packages (from torch>1.7.0->hummingbird-ml) (3.13.1)\n",
                        "Requirement already satisfied: fsspec in /Users/ethancemer/Documents/development/ezkl/.env/lib/python3.9/site-packages (from torch>1.7.0->hummingbird-ml) (2023.12.2)\n",
                        "Requirement already satisfied: typing-extensions in /Users/ethancemer/Documents/development/ezkl/.env/lib/python3.9/site-packages (from torch>1.7.0->hummingbird-ml) (4.9.0)\n",
                        "Requirement already satisfied: sympy in /Users/ethancemer/Documents/development/ezkl/.env/lib/python3.9/site-packages (from torch>1.7.0->hummingbird-ml) (1.12)\n",
                        "Requirement already satisfied: jinja2 in /Users/ethancemer/Documents/development/ezkl/.env/lib/python3.9/site-packages (from torch>1.7.0->hummingbird-ml) (3.1.2)\n",
                        "Collecting threadpoolctl>=2.0.0\n",
                        "  Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
                        "Collecting joblib>=1.1.1\n",
                        "  Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ethancemer/Documents/development/ezkl/.env/lib/python3.9/site-packages (from jinja2->torch>1.7.0->hummingbird-ml) (2.1.3)\n",
                        "Requirement already satisfied: mpmath>=0.19 in /Users/ethancemer/Documents/development/ezkl/.env/lib/python3.9/site-packages (from sympy->torch>1.7.0->hummingbird-ml) (1.3.0)\n",
                        "Installing collected packages: threadpoolctl, scipy, protobuf, joblib, dill, scikit-learn, onnxconverter-common, hummingbird-ml\n",
                        "  Attempting uninstall: protobuf\n",
                        "    Found existing installation: protobuf 4.25.1\n",
                        "    Uninstalling protobuf-4.25.1:\n",
                        "      Successfully uninstalled protobuf-4.25.1\n",
                        "Successfully installed dill-0.3.7 hummingbird-ml-0.4.9 joblib-1.3.2 onnxconverter-common-1.14.0 protobuf-3.20.2 scikit-learn-1.3.2 scipy-1.11.4 threadpoolctl-3.2.0\n",
                        "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
                        "You should consider upgrading via the '/Users/ethancemer/Documents/development/ezkl/.env/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
                        "\u001b[0m"
                    ]
                }
            ],
            "source": [
                "!pip install hummingbird-ml"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "95613ee9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# check if notebook is in colab\n",
                "try:\n",
                "    # install ezkl\n",
                "    import google.colab\n",
                "    import subprocess\n",
                "    import sys\n",
                "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ezkl\"])\n",
                "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"onnx\"])\n",
                "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"hummingbird-ml\"])\n",
                "\n",
                "# rely on local installation of ezkl if the notebook is not in colab\n",
                "except:\n",
                "    pass\n",
                "\n",
                "import os\n",
                "import torch\n",
                "import ezkl\n",
                "import json\n",
                "from hummingbird.ml import convert\n",
                "\n",
                "\n",
                "# here we create and (potentially train a model)\n",
                "\n",
                "# make sure you have the dependencies required here already installed\n",
                "import numpy as np\n",
                "from sklearn.linear_model import LinearRegression\n",
                "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
                "# y = 1 * x_0 + 2 * x_1 + 3\n",
                "y = np.dot(X, np.array([1, 2])) + 3\n",
                "reg = LinearRegression().fit(X, y)\n",
                "reg.score(X, y)\n",
                "\n",
                "circuit = convert(reg, \"torch\", X[:1]).model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "b37637c4",
            "metadata": {},
            "outputs": [],
            "source": [
                "model_path = os.path.join('network.onnx')\n",
                "compiled_model_path = os.path.join('network.compiled')\n",
                "pk_path = os.path.join('test.pk')\n",
                "vk_path = os.path.join('test.vk')\n",
                "settings_path = os.path.join('settings.json')\n",
                "\n",
                "witness_path = os.path.join('witness.json')\n",
                "data_path = os.path.join('input.json')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# export to onnx format\n",
                "# !!!!!!!!!!!!!!!!! This will flash a warning but it is fine !!!!!!!!!!!!!!!!!!!!!\n",
                "\n",
                "# Input to the model\n",
                "shape = X.shape[1:]\n",
                "# read in ./input_json\n",
                "data = json.load(open(\"input.json\", 'r'))\n",
                "# convert to torch tensor\n",
                "x = torch.tensor(data['input_data'], requires_grad=True)\n",
                "torch_out = circuit(x)\n",
                "# Export the model\n",
                "torch.onnx.export(circuit,               # model being run\n",
                "                  # model input (or a tuple for multiple inputs)\n",
                "                  x,\n",
                "                  # where to save the model (can be a file or file-like object)\n",
                "                  \"network.onnx\",\n",
                "                  export_params=True,        # store the trained parameter weights inside the model file\n",
                "                  opset_version=10,          # the ONNX version to export the model to\n",
                "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
                "                  input_names=['input'],   # the model's input names\n",
                "                  output_names=['output'],  # the model's output names\n",
                "                  dynamic_axes={'input': {0: 'batch_size'},    # variable length axes\n",
                "                                'output': {0: 'batch_size'}})\n",
                "\n",
                "d = ((x).detach().numpy()).reshape([-1]).tolist()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "d5e374a2",
            "metadata": {},
            "outputs": [],
            "source": [
                "!RUST_LOG=trace\n",
                "# TODO: Dictionary outputs\n",
                "res = ezkl.gen_settings(model_path, settings_path)\n",
                "assert res == True\n",
                "\n",
                "res = ezkl.calibrate_settings(data_path, model_path, settings_path, \"resources\")\n",
                "assert res == True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "3aa4f090",
            "metadata": {},
            "outputs": [],
            "source": [
                "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
                "assert res == True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "8b74dcee",
            "metadata": {},
            "outputs": [],
            "source": [
                "# srs path\n",
                "res = ezkl.get_srs(settings_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "18c8b7c7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# now generate the witness file \n",
                "\n",
                "res = ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
                "assert os.path.isfile(witness_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "b1c561a8",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "spawning module 2\n",
                        "spawning module 2\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "# HERE WE SETUP THE CIRCUIT PARAMS\n",
                "# WE GOT KEYS\n",
                "# WE GOT CIRCUIT PARAMETERS\n",
                "# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
                "\n",
                "\n",
                "\n",
                "res = ezkl.setup(\n",
                "        compiled_model_path,\n",
                "        vk_path,\n",
                "        pk_path,\n",
                "        \n",
                "    )\n",
                "\n",
                "assert res == True\n",
                "assert os.path.isfile(vk_path)\n",
                "assert os.path.isfile(pk_path)\n",
                "assert os.path.isfile(settings_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "c384cbc8",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "spawning module 2\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PROOF GENERATION TIME:  0.04433393478393555\n"
                    ]
                },
                {
                    "ename": "KeyError",
                    "evalue": "'ee'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[17], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m     benchmark \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Update the proving time in the loaded benchmark\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[43mbenchmark\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlinear_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mee\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprovingTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m proving_time\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Write the updated benchmark back to the file\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(benchmark_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
                        "\u001b[0;31mKeyError\u001b[0m: 'ee'"
                    ]
                }
            ],
            "source": [
                "# GENERATE A PROOF\n",
                "import time\n",
                "\n",
                "proof_path = os.path.join('test.pf')\n",
                "# log time it takes to generate proof\n",
                "start = time.time()\n",
                "res = ezkl.prove(\n",
                "        witness_path,\n",
                "        compiled_model_path,\n",
                "        pk_path,\n",
                "        proof_path,\n",
                "        \"single\",\n",
                "    )\n",
                "end = time.time()\n",
                "proving_time = end - start\n",
                "print(\"PROOF GENERATION TIME: \", proving_time)\n",
                "\n",
                "# define the path that stores the benchmarking results\n",
                "benchmark_path = os.path.join('../../benchmarks.json')\n",
                "\n",
                "# check that a benchmark path exists. If not, create one. Otherwise, load the existing one\n",
                "if not os.path.isfile(benchmark_path):\n",
                "    data = {\n",
                "        \"linear_regression\": {\n",
                "            \"ezkl\": {\n",
                "                \"provingTime\": proving_time\n",
                "            },\n",
                "            \"riscZero\": {}\n",
                "        }\n",
                "    }\n",
                "    with open(benchmark_path, 'w') as f:\n",
                "        json.dump(data, open(benchmark_path, 'w'))\n",
                "else:\n",
                "    with open(benchmark_path, 'r') as f:\n",
                "        benchmark = json.load(f)\n",
                "\n",
                "    # Update the proving time in the loaded benchmark\n",
                "    benchmark['linear_regression']['ezkl']['provingTime'] = proving_time\n",
                "\n",
                "    # Write the updated benchmark back to the file\n",
                "    with open(benchmark_path, 'w') as f:\n",
                "        json.dump(benchmark, f, indent=4)\n",
                "\n",
                "\n",
                "print(res)\n",
                "print(res['instances'])\n",
                "assert os.path.isfile(proof_path)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
